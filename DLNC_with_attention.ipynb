{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4eLpmHf0W75"
      },
      "source": [
        "# google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuNjVGLw0ZVt",
        "outputId": "a32cd844-fd39-46b1-de6b-7b447b2ff775"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPbfUABL2TsE"
      },
      "source": [
        "# Loading Embedding_matrix & Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ocGvBZmn2YlT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "# Read dictionary pkl file\n",
        "with open(\"/content/gdrive/My Drive/matrices/vocab.pkl\", 'rb') as fp:\n",
        "    vocab= pickle.load(fp)\n",
        "\n",
        "matrix_name = \"Glove_embedding_matrix.npy\"\n",
        "path= F\"/content/gdrive/My Drive/matrices/{matrix_name}\"\n",
        "\n",
        "embedding_matrix = np.load(path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zK2ENbm250rA"
      },
      "outputs": [],
      "source": [
        "vocab_size = np.shape(embedding_matrix)[0]\n",
        "embedding_dim = np.shape(embedding_matrix)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAKn6BIv01WZ"
      },
      "source": [
        "# Dataset Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GMgQdejfGyu"
      },
      "source": [
        "## Emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "15L2HEzC0a4t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "raw-PBGF06AQ"
      },
      "outputs": [],
      "source": [
        "ds_name = \"emotion_train.csv\"\n",
        "path= F\"/content/gdrive/My Drive/Database/{ds_name}\"\n",
        "ds = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4FX6CGw51DHA"
      },
      "outputs": [],
      "source": [
        "emotion_text = ds['text']\n",
        "emotion_label = ds['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaJiebA7p3zL",
        "outputId": "76c57dbf-fc21-4a3a-a20a-f643255ffe9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4179\n"
          ]
        }
      ],
      "source": [
        "print(len(emotion_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GBCWl2V01Ugz"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import numpy\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbPSz45yG4td",
        "outputId": "96affbc9-6c34-4ae3-8c85-536cc3756b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['i', 'dont', 'understand', 'why', 'u', 'do', 'videos', 'every', 'week', 'spend', 'time', 'with', 'your', 'family', 'instead', 'of', 'working', 'on', 'horror', '#takeabreak']\n"
          ]
        }
      ],
      "source": [
        "b = emotion_text[0]\n",
        "b = str.split(b, ' ')\n",
        "b = [i for i in b if not '@' in i]\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9pio7Q6ASDp"
      },
      "source": [
        "## Yelp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M0msGYrlAU61"
      },
      "outputs": [],
      "source": [
        "ds_name = \"yelp_train.csv\"\n",
        "path= F\"/content/gdrive/My Drive/Database/{ds_name}\"\n",
        "ds = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vRX61vHeAdkl"
      },
      "outputs": [],
      "source": [
        "yelp_text = ds['text']\n",
        "yelp_label = ds['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeOYWOF9qEA0",
        "outputId": "cca5626b-32aa-409d-eb63-ecb67a2c551d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5000\n"
          ]
        }
      ],
      "source": [
        "print(len(yelp_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMfycNZx2EG6"
      },
      "source": [
        "# Classification Data_preprocess & Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hV-sn95X2Apq"
      },
      "outputs": [],
      "source": [
        "class Preprocess_classification:\n",
        "    def __init__(self, vocab):\n",
        "      self.vocab = vocab\n",
        "      self.stop_words = ['is','was','be','will','the','on','a','an','about','any','all','both','ain','after','because','at','be','before','been','can','could','during','for','to','about','just','such','then','which']\n",
        "\n",
        "    def preprocess_sentence(self, w):\n",
        "      import re\n",
        "      #Lower\n",
        "      w = w.lower().strip()\n",
        "\n",
        "      # removing @s (for tweets)\n",
        "      w = str.split(w,' ')\n",
        "      w = [x for x in w if not '@' in x]\n",
        "      w = ' '.join(w)\n",
        "\n",
        "      # creating a space between a word and the punctuation following it\n",
        "      w = re.sub(r\"([?.!,¿:])\", r\" \\1 \", w)\n",
        "      w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "      # replacing everything with space except (a-z, A-Z,\":\", \"?\", \"!\", \",\")\n",
        "      w = re.sub(r\"[^a-zA-Z?!,¿:]+\", \" \", w)\n",
        "\n",
        "      # removing stop-words\n",
        "      w = str.split(w,' ')\n",
        "      w = [x for x in w if not x in self.stop_words]\n",
        "      w = ' '.join(w)\n",
        "\n",
        "      # outputting the (Glove)vocab values\n",
        "      w = w.split()\n",
        "      w = [word if word in self.vocab else '' for word in w]\n",
        "      Out = [self.vocab[word] for word in w if word!= '']\n",
        "      return Out\n",
        "\n",
        "    def create_dataset(self, text, label, max_len, buffer_size, batch_size):\n",
        "      Text = np.array([self.preprocess_sentence(w) for w in text])\n",
        "      Label = np.array(label)\n",
        "\n",
        "      # padding\n",
        "      Text = tf.keras.preprocessing.sequence.pad_sequences(Text, maxlen= max_len, padding='post')\n",
        "\n",
        "      train_dataset = tf.data.Dataset.from_tensor_slices((Text, Label))\n",
        "      train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "      return train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atnvhjFPFv26",
        "outputId": "a922f6dd-e6bc-4c38-c72d-8dab06b54a41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-79cb1ed4c48f>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  Text = np.array([self.preprocess_sentence(w) for w in text])\n"
          ]
        }
      ],
      "source": [
        "# For EI_emotion\n",
        "buffer_size_emotion = 4500\n",
        "batch_size = 64\n",
        "max_len = 25\n",
        "\n",
        "preprocess = Preprocess_classification(vocab)\n",
        "train_emotion = preprocess.create_dataset(emotion_text, emotion_label, max_len, buffer_size_emotion, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIqUucGvED43",
        "outputId": "756137fb-4382-449c-de90-14a02776cb73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-79cb1ed4c48f>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  Text = np.array([self.preprocess_sentence(w) for w in text])\n"
          ]
        }
      ],
      "source": [
        "buffer_size_sentiment = 5500\n",
        "\n",
        "train_sentiment = preprocess.create_dataset(yelp_text, yelp_label, max_len, buffer_size_sentiment, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tmjhh_ohI49",
        "outputId": "62979c3a-4ff1-400d-e009-927381423126"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([64, 25]), TensorShape([64]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_input_batch_emotion, example_target_batch_emotion = next(iter(train_sentiment))\n",
        "example_input_batch_emotion.shape, example_target_batch_emotion.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg7Lldg3E4Ag"
      },
      "source": [
        "# Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSPtqv2eE84K"
      },
      "outputs": [],
      "source": [
        "# Basic Classifier class\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "class Basic_Classifier(tf.keras.Model):\n",
        "  def __init__(self, units, batch_size, num_classes, recurrent_dropout= 0.3):\n",
        "    super(Basic_Classifier, self).__init__()\n",
        "    self.batch_size = batch_size\n",
        "    self.units = units\n",
        "    self.recurrent_dropout = recurrent_dropout\n",
        "    self.num_classes = num_classes\n",
        "\n",
        "    self.embedding_layer = tf.keras.layers.Embedding(\n",
        "    input_dim=vocab_size,\n",
        "    output_dim=embedding_dim,\n",
        "    weights=[embedding_matrix],\n",
        "    mask_zero=True,\n",
        "    trainable=True)\n",
        "\n",
        "    self.lstm_layer = tf.keras.layers.LSTM(self.units, return_sequences= True, return_state= True, recurrent_dropout= self.recurrent_dropout)\n",
        "    self.linear_layer = Dense(units=32, activation='relu')\n",
        "    self.softmax_layer = Dense(units=self.num_classes, activation='softmax')\n",
        "\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding_layer(x)\n",
        "\n",
        "    output, h, c = self.lstm_layer(x, initial_state= hidden)\n",
        "    dropout_hidden = tf.keras.layers.Dropout(rate=0.3)(h)\n",
        "\n",
        "    linear = self.linear_layer(h)\n",
        "    dropout_linear = tf.keras.layers.Dropout(rate=0.2)(linear)\n",
        "\n",
        "    softmax = self.softmax_layer(dropout_linear)\n",
        "    return softmax\n",
        "\n",
        "  def initialize_hidden_state(self, batch_size):\n",
        "    return [tf.zeros((batch_size, self.units)), tf.zeros((batch_size, self.units))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruaMeKQvQnvy"
      },
      "outputs": [],
      "source": [
        "a = Basic_Classifier(256, 64, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnBJPVKuQwxx"
      },
      "outputs": [],
      "source": [
        "# Test\n",
        "h, c = a.initialize_hidden_state(64)\n",
        "a.call(example_input_batch_emotion, [h,c])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPV563v0E9Rn"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "import tensorflow as tf\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(0.001)\n",
        "\n",
        "#Loss\n",
        "def loss_function(real, pred):\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  loss = cross_entropy(y_true= real, y_pred= pred)\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72PY8LTEXE09"
      },
      "outputs": [],
      "source": [
        "# Defining model instances\n",
        "batch_size = 64\n",
        "classifier_emotion_base = Basic_Classifier(batch_size= batch_size, units= 256, num_classes= 4)\n",
        "classifier_sentiment_base = Basic_Classifier(batch_size= batch_size, units= 256, num_classes= 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BAdX-NWbbm8"
      },
      "outputs": [],
      "source": [
        "steps_emotion= len(emotion_text)//batch_size\n",
        "steps_sentiment = len(yelp_text)//batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbn982bQdLgb"
      },
      "outputs": [],
      "source": [
        "def train_step_base(model, text, label):\n",
        "  h, c = model.initialize_hidden_state(batch_size)\n",
        "  with tf.GradientTape() as tape:\n",
        "    out_probs = model.call(text, [h,c])\n",
        "\n",
        "    predicted_labels = tf.argmax(out_probs, axis=-1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(label, predicted_labels), dtype=tf.float32))\n",
        "    # Loss\n",
        "    loss = loss_function(label, out_probs)\n",
        "    # Get the watched variables\n",
        "    variables = model.trainable_variables\n",
        "\n",
        "    # Compute gradients only for watched variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    # Apply gradients to the watched variables\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBzk-NHsM3Xg"
      },
      "outputs": [],
      "source": [
        "def train_epoch_base(model, data_set, steps, epochs):\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    for (batch, (text, label)) in enumerate(data_set.take(steps)):\n",
        "      batch_loss, batch_accuracy = train_step_base(model, text, label)\n",
        "      total_loss += batch_loss\n",
        "      total_accuracy += batch_accuracy\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch+1,\n",
        "                                        total_loss / steps))\n",
        "    print('Epoch {} Accuracy {:.4f}'.format(epoch+1,\n",
        "                                        total_accuracy ))\n",
        "    losses.append(total_loss/steps)\n",
        "    accuracies.append(total_accuracy/steps)\n",
        "\n",
        "  return losses, accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPpruSRnPKon",
        "outputId": "376f7137-c8ef-4d17-8330-20154e418d24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 1.1378\n",
            "Epoch 1 Accuracy 31.9688\n",
            "Epoch 2 Loss 0.7470\n",
            "Epoch 2 Accuracy 46.0156\n",
            "Epoch 3 Loss 0.5068\n",
            "Epoch 3 Accuracy 53.0156\n",
            "Epoch 4 Loss 0.3743\n",
            "Epoch 4 Accuracy 55.9062\n",
            "Epoch 5 Loss 0.2997\n",
            "Epoch 5 Accuracy 57.9688\n",
            "Epoch 6 Loss 0.2570\n",
            "Epoch 6 Accuracy 58.5625\n",
            "Epoch 7 Loss 0.2216\n",
            "Epoch 7 Accuracy 59.4688\n",
            "Epoch 8 Loss 0.1929\n",
            "Epoch 8 Accuracy 59.8281\n",
            "Epoch 9 Loss 0.1637\n",
            "Epoch 9 Accuracy 60.0781\n",
            "Epoch 10 Loss 0.1523\n",
            "Epoch 10 Accuracy 60.3906\n"
          ]
        }
      ],
      "source": [
        "losses_emotion_base, accuracies_emotion_base = train_epoch_base(classifier_emotion_base, train_emotion, len(emotion_text)//batch_size, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "_nngMC1H6dCv",
        "outputId": "ca0b7f70-30eb-4ee3-cd31-2030d9264d00"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample accuracy data for 8 training epochs\n",
        "epoch_numbers = [1, 2, 3, 4, 5, 6, 7, 8,9,10]\n",
        "accuracies = accuracies_emotion_base\n",
        "losses = losses_emotion_base\n",
        "\n",
        "# Plotting the accuracies\n",
        "plt.plot(epoch_numbers, accuracies, marker='o', linestyle='-')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Emotion Accuracy Over Epochs')\n",
        "\n",
        "# Adding grid for better readability\n",
        "plt.grid(True)\n",
        "\n",
        "# Saving the plot as a PNG file\n",
        "plt.savefig('training_emotion_accuracy.png')\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnWRu0qZJBua",
        "outputId": "82f34047-7dd0-44bc-d4a2-118f59684e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.9777\n",
            "Epoch 1 Accuracy 42.3438\n",
            "Epoch 2 Loss 0.7545\n",
            "Epoch 2 Accuracy 52.7031\n",
            "Epoch 3 Loss 0.5833\n",
            "Epoch 3 Accuracy 59.4375\n",
            "Epoch 4 Loss 0.4157\n",
            "Epoch 4 Accuracy 65.3750\n",
            "Epoch 5 Loss 0.2732\n",
            "Epoch 5 Accuracy 70.1719\n",
            "Epoch 6 Loss 0.1766\n",
            "Epoch 6 Accuracy 73.1562\n",
            "Epoch 7 Loss 0.1067\n",
            "Epoch 7 Accuracy 75.2812\n",
            "Epoch 8 Loss 0.0686\n",
            "Epoch 8 Accuracy 76.3594\n",
            "Epoch 9 Loss 0.0399\n",
            "Epoch 9 Accuracy 77.1094\n",
            "Epoch 10 Loss 0.0253\n",
            "Epoch 10 Accuracy 77.4688\n",
            "Epoch 11 Loss 0.0138\n",
            "Epoch 11 Accuracy 77.7031\n",
            "Epoch 12 Loss 0.0059\n",
            "Epoch 12 Accuracy 77.8750\n"
          ]
        }
      ],
      "source": [
        "losses_sentiment_base, accuracies_sentiment_base = train_epoch_base(classifier_sentiment_base, train_sentiment, len(yelp_text)//batch_size, 14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kmnfIgTjDxR"
      },
      "source": [
        "# LN-LSTM Encoder cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "k377OFxsFKm-"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# To DO: trainability of layers (for fine-tuning)\n",
        "class LNLSTMCell(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, hidden_size, trainable=True, dropout=0.3):\n",
        "        super(LNLSTMCell, self).__init__()\n",
        "        self.input_size = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.trainable = trainable\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.ln_emotion_x = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_emotion_h = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_emotion_c = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "        self.ln_sentiment_x = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_sentiment_h = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_sentiment_c = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "        self.ln_new_x = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_new_h = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_new_c = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout_layer = tf.keras.layers.Dropout(rate= dropout)\n",
        "\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(\n",
        "          input_dim=vocab_size,\n",
        "          output_dim=embedding_dim,\n",
        "          weights=[embedding_matrix],\n",
        "          mask_zero=True,\n",
        "          trainable=True)\n",
        "\n",
        "        # LSTM parameters\n",
        "        self.weight_ih = self.add_weight(shape=(self.input_size, 4 * hidden_size), trainable= self.trainable)\n",
        "        self.weight_ih_with_dropout = self.dropout_layer(self.weight_ih)\n",
        "        self.weight_hh = self.add_weight(shape=(hidden_size, 4 * hidden_size), trainable= self.trainable)\n",
        "        self.weight_hh_with_dropout = self.dropout_layer(self.weight_hh)\n",
        "        self.bias = self.add_weight(shape=(4 * hidden_size,), trainable= self.trainable)\n",
        "        self.bias_with_dropout = self.dropout_layer(self.bias)\n",
        "\n",
        "\n",
        "    def call(self, task, input_, hx):\n",
        "        h, c = hx\n",
        "        if task == 'emotion':\n",
        "          ln_x = self.ln_emotion_x\n",
        "          ln_h = self.ln_emotion_h\n",
        "          ln_c = self.ln_emotion_c\n",
        "\n",
        "        elif task == 'sentiment':\n",
        "          ln_x = self.ln_sentiment_x\n",
        "          ln_h = self.ln_sentiment_h\n",
        "          ln_c = self.ln_sentiment_c\n",
        "\n",
        "        elif task == 'new':\n",
        "          ln_x = self.ln_new_x\n",
        "          ln_h = self.ln_new_h\n",
        "          ln_c = self.ln_new_c\n",
        "        else:\n",
        "          raise ValueError('Key Error')\n",
        "\n",
        "        input = self.embedding_layer(input_)\n",
        "\n",
        "        # Create a mask for the input based on non-zero values\n",
        "        mask = tf.math.not_equal(input_, 0)\n",
        "        mask = tf.cast(mask, dtype=input.dtype)\n",
        "        # Broadcast the mask to match the shape of gates\n",
        "        mask = tf.expand_dims(mask, axis=-1)\n",
        "\n",
        "\n",
        "        gates = ln_x(tf.matmul(input, self.weight_ih_with_dropout)) + ln_h(tf.matmul(h, self.weight_hh_with_dropout)) + self.bias_with_dropout\n",
        "\n",
        "\n",
        "        # Split the gates into input, forget, cell, and output gates\n",
        "        input_gate, forget_gate, cell_gate, output_gate = tf.split(gates, 4, axis=-1)\n",
        "\n",
        "        # Apply sigmoid activation to the gates\n",
        "        input_gate = tf.sigmoid(input_gate)\n",
        "        forget_gate = tf.sigmoid(forget_gate)\n",
        "        cell_gate = tf.tanh(cell_gate)\n",
        "        output_gate = tf.sigmoid(output_gate)\n",
        "\n",
        "        # Update the cell and hidden state\n",
        "        c_new = c * forget_gate + input_gate * cell_gate\n",
        "        c_new = c_new * mask + c * (1 - mask)  # Masked cell state remains unchanged\n",
        "        h_new = output_gate * tf.tanh(ln_c(c_new))\n",
        "        h_new = h_new * mask + h * (1 - mask)  # Masked hidden state remains unchanged\n",
        "\n",
        "        return h_new, c_new\n",
        "\n",
        "    def initialize_hidden_state(self, batch_size):\n",
        "      return [tf.zeros((batch_size, self.hidden_size)), tf.zeros((batch_size, self.hidden_size))]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "UwAyadaCAsze"
      },
      "outputs": [],
      "source": [
        "seq_len = np.shape(example_input_batch_emotion)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UtuWFNsviy3a"
      },
      "outputs": [],
      "source": [
        "ln_lstm = LNLSTMCell(embedding_dim= embedding_dim, hidden_size= 128, trainable=True)\n",
        "outputs = tf.TensorArray(tf.float32, size=seq_len)\n",
        "\n",
        "for t in range(seq_len):\n",
        "  x = example_input_batch_emotion[:, t]\n",
        "  initial = ln_lstm.initialize_hidden_state(batch_size=batch_size)\n",
        "  h, c = ln_lstm.call('emotion',x, initial)\n",
        "  outputs = outputs.write(t, h)\n",
        "outputs = outputs.stack()\n",
        "outputs = tf.transpose(outputs, [1,0,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI8Im_msBr5l",
        "outputId": "c826c581-f0e7-4c55-8c65-d4e68576b08c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 25, 128)\n"
          ]
        }
      ],
      "source": [
        "print(np.shape(outputs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8dED1YoDlWH"
      },
      "source": [
        "# MultiTaskClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQktrwEkq2mY"
      },
      "source": [
        "## Task Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tjUm6MK5q1QA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class TaskEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_tasks, embedding_dim, trainable=True):\n",
        "        super(TaskEmbedding, self).__init__()\n",
        "        self.num_tasks = num_tasks\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # Create a trainable weight variable for this layer.\n",
        "        self.embedding_weights = self.add_weight(\n",
        "            shape=(num_tasks, embedding_dim),\n",
        "            initializer='random_normal',\n",
        "            trainable=trainable\n",
        "        )\n",
        "\n",
        "    def call(self, task_indices):\n",
        "        # Retrieve task embeddings based on task indices\n",
        "        task_embeddings = tf.nn.embedding_lookup(self.embedding_weights, task_indices)\n",
        "        return task_embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SxOlEPLmrEEM"
      },
      "outputs": [],
      "source": [
        "# Testing :\n",
        "\n",
        "# Define the number of tasks and embedding dimension\n",
        "num_tasks = 3\n",
        "\n",
        "# Create an instance of TaskEmbedding\n",
        "task_embedding = TaskEmbedding(num_tasks, 32)\n",
        "\n",
        "# Create a tensor of task indices\n",
        "task_indices = tf.constant([0, 1, 2], dtype=tf.int32)\n",
        "\n",
        "# Get task embeddings\n",
        "task_embeddings = task_embedding(task_indices)\n",
        "\n",
        "# The task_embeddings tensor will contain the trainable embeddings for each task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KZeLUlVM63ME"
      },
      "outputs": [],
      "source": [
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super(LuongAttention, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "\n",
        "        #Attention LN\n",
        "        self.ln_emotion_a = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_sentiment_a = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_new_a = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "        self.attention_weights = self.add_weight(\n",
        "            name='attention_weights',\n",
        "            shape=(self.units, self.units),\n",
        "            initializer='uniform',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "\n",
        "    def call(self, encoder_outputs, decoder_hidden, task):\n",
        "        if task == 'emotion':\n",
        "          ln_a = self.ln_emotion_a\n",
        "\n",
        "        elif task == 'sentiment':\n",
        "          ln_a = self.ln_sentiment_a\n",
        "\n",
        "        elif task == 'new':\n",
        "          ln_a = self.ln_new_a\n",
        "\n",
        "        else:\n",
        "          raise ValueError('Key Error')\n",
        "\n",
        "        # Expand dimensions of decoder hidden state for compatibility\n",
        "        decoder_hidden_with_time_axis = tf.expand_dims(decoder_hidden, axis=1)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        attention_scores = ln_a(tf.matmul(decoder_hidden_with_time_axis, self.attention_weights))\n",
        "        attention_scores = tf.matmul(attention_scores, encoder_outputs, transpose_b=True)\n",
        "\n",
        "        # Apply softmax to get attention weights\n",
        "        attention_weights = tf.nn.softmax(attention_scores, axis=-1)\n",
        "\n",
        "        # Apply attention weights to encoder outputs\n",
        "        context_vector = tf.matmul(attention_weights, encoder_outputs)\n",
        "\n",
        "        context_vec = tf.reshape(context_vector, (np.shape(context_vector)[0], np.shape(context_vector)[-1]))\n",
        "        attention_weights = tf.reshape(attention_weights, (np.shape(attention_weights)[0], np.shape(attention_weights)[-1]))\n",
        "\n",
        "        return context_vector, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwn_KdkbqElC"
      },
      "source": [
        "## LN-LSTM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "gWbo0OD2qC1V"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# To DO: trainability of layers (for fine-tuning)\n",
        "class LNLSTMClassifier_with_Attention(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, hidden_size, dropout=0.3, trainable=True, num_classes_emotion=4, num_classes_sentiment=3):\n",
        "        super(LNLSTMClassifier_with_Attention, self).__init__()\n",
        "        self.input_size = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "\n",
        "        # get task specific embedding\n",
        "        self.task_embedding = TaskEmbedding(num_tasks=2, embedding_dim= self.input_size)\n",
        "        self.Attention = LuongAttention(self.hidden_size)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout_layer = tf.keras.layers.Dropout(rate=dropout)\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.ln_emotion_x = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_emotion_h = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_emotion_c = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "        self.ln_sentiment_x = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_sentiment_h = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_sentiment_c = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "        self.ln_new_x = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_new_h = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_new_c = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "        # LSTM parameters\n",
        "        self.weight_ih = self.add_weight(shape=(self.input_size, 4 * hidden_size), trainable= trainable)\n",
        "        self.weight_ih_with_dropout = self.dropout_layer(self.weight_ih)\n",
        "        self.weight_hh = self.add_weight(shape=(hidden_size, 4 * hidden_size), trainable= trainable)\n",
        "        self.weight_hh_with_dropout = self.dropout_layer(self.weight_hh)\n",
        "        self.bias = self.add_weight(shape=(4 * hidden_size,), trainable= trainable)\n",
        "        self.bias_with_dropout = self.dropout_layer(self.bias)\n",
        "\n",
        "        # Classification parameters\n",
        "        self.dense_emotion_h_1 = Dense(units=16, activation='relu')\n",
        "        self.dense_emotion_h_2 = Dense(units=4, activation='relu')\n",
        "        self.dense_emotion_c_1 = Dense(units=16, activation='relu')\n",
        "        self.dense_emotion_c_2 = Dense(units=4, activation='relu')\n",
        "        self.softmax_emotion = Dense(units=num_classes_emotion, activation='softmax')\n",
        "\n",
        "\n",
        "        self.dense_sentiment_h_1 = Dense(units=16, activation='relu')\n",
        "        self.dense_sentiment_h_2 = Dense(units=4, activation='relu')\n",
        "        self.dense_sentiment_c_1 = Dense(units=16, activation='relu')\n",
        "        self.dense_sentiment_c_2 = Dense(units=4, activation='relu')\n",
        "        self.softmax_sentiment = Dense(units=num_classes_sentiment, activation='softmax')\n",
        "\n",
        "        self.dense_new_h_1 = Dense(units=16, activation='relu')\n",
        "        self.dense_new_h_2 = Dense(units=4, activation='relu')\n",
        "        self.dense_new_c_1 = Dense(units=16, activation='relu')\n",
        "        self.dense_new_c_2 = Dense(units=4, activation='relu')\n",
        "        self.softmax_new = Dense(units=num_classes_sentiment, activation='softmax')\n",
        "\n",
        "\n",
        "    def call(self, task, task_indices, hx, encoder_outputs):\n",
        "        h, c = hx\n",
        "\n",
        "        if task == 'emotion':\n",
        "          ln_x = self.ln_emotion_x\n",
        "          ln_h = self.ln_emotion_h\n",
        "          ln_c = self.ln_emotion_c\n",
        "          dense_h_1 = self.dense_emotion_h_1\n",
        "          dense_h_2 = self.dense_emotion_h_2\n",
        "          dense_c_1 = self.dense_emotion_c_1\n",
        "          dense_c_2 = self.dense_emotion_c_2\n",
        "          soft_max = self.softmax_emotion\n",
        "\n",
        "        elif task == 'sentiment':\n",
        "          ln_x = self.ln_sentiment_x\n",
        "          ln_h = self.ln_sentiment_h\n",
        "          ln_c = self.ln_sentiment_c\n",
        "          dense_h_1 = self.dense_sentiment_h_1\n",
        "          dense_h_2 = self.dense_sentiment_h_2\n",
        "          dense_c_1 = self.dense_sentiment_c_1\n",
        "          dense_c_2 = self.dense_sentiment_c_2\n",
        "          soft_max = self.softmax_sentiment\n",
        "\n",
        "        elif task == 'new':\n",
        "          ln_x = self.ln_new_x\n",
        "          ln_h = self.ln_new_h\n",
        "          ln_c = self.ln_new_c\n",
        "          dense_h_1 = self.dense_new_h_1\n",
        "          dense_h_2 = self.dense_new_h_2\n",
        "          dense_c_1 = self.dense_new_c_1\n",
        "          dense_c_2 = self.dense_new_c_2\n",
        "          soft_max = self.softmax_new\n",
        "\n",
        "        else:\n",
        "          raise ValueError('Key Error')\n",
        "\n",
        "\n",
        "        input = self.task_embedding(task_indices)\n",
        "\n",
        "        gates = ln_x(tf.matmul(input, self.weight_ih_with_dropout)) + ln_h(tf.matmul(h, self.weight_hh_with_dropout)) + self.bias_with_dropout\n",
        "\n",
        "        # Split the gates into input, forget, cell, and output gates\n",
        "        input_gate, forget_gate, cell_gate, output_gate = tf.split(gates, 4, axis=-1)\n",
        "\n",
        "        # Apply sigmoid activation to the gates\n",
        "        input_gate = tf.sigmoid(input_gate)\n",
        "        forget_gate = tf.sigmoid(forget_gate)\n",
        "        cell_gate = tf.tanh(cell_gate)\n",
        "        output_gate = tf.sigmoid(output_gate)\n",
        "\n",
        "        # Update the cell and hidden state\n",
        "        c_new = c * forget_gate + input_gate * cell_gate\n",
        "        h_new = output_gate * tf.tanh(ln_c(c_new))\n",
        "        context_vector, attention_weights = self.Attention(encoder_outputs, h_new, task)\n",
        "        h_new = self.dropout_layer(h_new)\n",
        "        h_new = dense_h_1(h_new)\n",
        "        h_new = dense_h_2(h_new)\n",
        "\n",
        "        context_vector = tf.reshape(context_vector, (np.shape(context_vector)[0], np.shape(context_vector)[-1]))\n",
        "        context_vector = self.dropout_layer(context_vector)\n",
        "        context_vector = dense_c_1(context_vector)\n",
        "        context_vector = dense_c_2(context_vector)\n",
        "\n",
        "        new_hidden = tf.concat([h_new, context_vector], axis= -1)\n",
        "\n",
        "        # Classify using hidden state\n",
        "        output = soft_max(new_hidden)\n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "    def initialize_hidden_state(self, batch_size): # actually, not necessary, cause gets inputs from encoder\n",
        "      return [tf.zeros((batch_size, self.hidden_size)), tf.zeros((batch_size, self.hidden_size))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "swFTVZ5LvCD9"
      },
      "outputs": [],
      "source": [
        "ln_classifier = LNLSTMClassifier_with_Attention(embedding_dim=16, hidden_size=128, dropout=0.3)\n",
        "z = tf.constant([0 for i in range(batch_size)], dtype=tf.int32)\n",
        "out, attention_weights = ln_classifier.call(task='new',task_indices=z, hx=[h,c], encoder_outputs = outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7w4AhWnpFl5"
      },
      "source": [
        "## Classifier(separate variables for each task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLdAX0loupIJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# To DO: trainability of layers (for fine-tuning)\n",
        "class MultiTaskClassifier(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, hidden_size, dropout=0.3, trainable=True, num_classes_emotion=4, num_classes_sentiment=3, num_classes_new=2):\n",
        "        super(MultiTaskClassifier, self).__init__()\n",
        "        self.input_size = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # get task specific embedding\n",
        "        self.task_embedding = TaskEmbedding(num_tasks=3, embedding_dim= self.input_size)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout_layer = tf.keras.layers.Dropout(rate=dropout)\n",
        "\n",
        "        self.weight_ih_emotion = self.add_weight(shape=(self.input_size, 4 * hidden_size))\n",
        "        self.weight_ih_emotion_with_dropout = self.dropout_layer(self.weight_ih_emotion)\n",
        "        self.weight_hh_emotion = self.add_weight(shape=(hidden_size, 4 * hidden_size))\n",
        "        self.weight_hh_emotion_with_dropout = self.dropout_layer(self.weight_hh_emotion)\n",
        "        self.bias_emotion = self.add_weight(shape=(4 * hidden_size,))\n",
        "        self.bias_emotion_with_dropout = self.dropout_layer(self.bias_emotion)\n",
        "        self.dense_emotion = Dense(units=32, activation='relu')\n",
        "        self.softmax_emotion = Dense(units=num_classes_emotion, activation='softmax')\n",
        "\n",
        "        self.weight_ih_sentiment = self.add_weight(shape=(self.input_size, 4 * hidden_size))\n",
        "        self.weight_ih_sentiment_with_dropout = self.dropout_layer(self.weight_ih_sentiment)\n",
        "        self.weight_hh_sentiment = self.add_weight(shape=(hidden_size, 4 * hidden_size))\n",
        "        self.weight_hh_sentiment_with_dropout = self.dropout_layer(self.weight_hh_sentiment)\n",
        "        self.bias_sentiment = self.add_weight(shape=(4 * hidden_size,))\n",
        "        self.bias_sentiment_with_dropout = self.dropout_layer(self.bias_sentiment)\n",
        "        self.dense_sentiment = Dense(units=32, activation='relu')\n",
        "        self.softmax_sentiment = Dense(units=num_classes_sentiment, activation='softmax')\n",
        "\n",
        "        self.weight_ih_new = self.add_weight(shape=(self.input_size, 4 * hidden_size))\n",
        "        self.weight_ih_new_with_dropout = self.dropout_layer(self.weight_ih_new)\n",
        "        self.weight_hh_new = self.add_weight(shape=(hidden_size, 4 * hidden_size))\n",
        "        self.weight_hh_new_with_dropout = self.dropout_layer(self.weight_hh_new)\n",
        "        self.bias_new = self.add_weight(shape=(4 * hidden_size,))\n",
        "        self.bias_new_with_dropout = self.dropout_layer(self.bias_new)\n",
        "        self.dense_new = Dense(units=32, activation='relu')\n",
        "        self.softmax_new = Dense(units=num_classes_new, activation='softmax') # num_classes_new could be different based on new task considered for fine tuning\n",
        "\n",
        "\n",
        "    def call(self, task, task_indices, hx):\n",
        "        h, c = hx\n",
        "        if task == 'emotion':\n",
        "          weight_ih = self.weight_ih_emotion_with_dropout\n",
        "          weight_hh = self.weight_hh_emotion_with_dropout\n",
        "          bias = self.bias_emotion_with_dropout\n",
        "          dense = self.dense_emotion\n",
        "          soft_max = self.softmax_emotion\n",
        "\n",
        "        elif task == 'sentiment':\n",
        "          weight_ih = self.weight_ih_sentiment_with_dropout\n",
        "          weight_hh = self.weight_hh_sentiment_with_dropout\n",
        "          bias = self.bias_sentiment_with_dropout\n",
        "          dense = self.dense_sentiment\n",
        "          soft_max = self.softmax_sentiment\n",
        "\n",
        "        elif task == 'new':\n",
        "          weight_ih = self.weight_ih_new_with_dropout\n",
        "          weight_hh = self.weight_hh_new_with_dropout\n",
        "          bias = self.bias_new_with_dropout\n",
        "          dense = self.dense_new\n",
        "          soft_max = self.softmax_new\n",
        "\n",
        "        else:\n",
        "          raise ValueError('Key Error')\n",
        "\n",
        "\n",
        "        input = self.task_embedding(task_indices)\n",
        "\n",
        "        gates = tf.matmul(input, weight_ih) + tf.matmul(h, weight_hh) + bias\n",
        "\n",
        "        # Split the gates into input, forget, cell, and output gates\n",
        "        input_gate, forget_gate, cell_gate, output_gate = tf.split(gates, 4, axis=-1)\n",
        "\n",
        "        # Apply sigmoid activation to the gates\n",
        "        input_gate = tf.sigmoid(input_gate)\n",
        "        forget_gate = tf.sigmoid(forget_gate)\n",
        "        cell_gate = tf.tanh(cell_gate)\n",
        "        output_gate = tf.sigmoid(output_gate)\n",
        "\n",
        "        # Update the cell and hidden state\n",
        "        c_new = c * forget_gate + input_gate * cell_gate\n",
        "        h_new = output_gate * tf.tanh(c_new)\n",
        "\n",
        "        # Classify using hidden state\n",
        "        dropout_hidden = tf.keras.layers.Dropout(rate=0.2)(h_new)\n",
        "        dense_output = dense(dropout_hidden)\n",
        "        dropout_dense = tf.keras.layers.Dropout(rate=0.1)(dense_output)\n",
        "        output = soft_max(dropout_dense)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def initialize_hidden_state(self, batch_size): # actually, not necessary, cause gets inputs from encoder\n",
        "      return [tf.zeros((batch_size, self.hidden_size)), tf.zeros((batch_size, self.hidden_size))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2bIHVBBFNYN"
      },
      "outputs": [],
      "source": [
        "classifier = MultiTaskClassifier(embedding_dim=32, hidden_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hLCv4nskdS5"
      },
      "outputs": [],
      "source": [
        "z = tf.constant([0 for i in range(batch_size)], dtype=tf.int32)\n",
        "out = classifier.call(task='emotion',task_indices=z, hx=[h,c])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjp2PPzZQkX-"
      },
      "source": [
        "## LN-LSTM Classifier without learnable Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "51I8rHMuQi0G"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "# To DO: trainability of layers (for fine-tuning)\n",
        "class LNLSTMClassifier_no_emb(tf.keras.Model):\n",
        "    def __init__(self, embedding_dim, hidden_size, dropout=0.3, trainable=True, num_classes_emotion=4, num_classes_sentiment=3, num_classes_new=2):\n",
        "        super(LNLSTMClassifier_no_emb, self).__init__()\n",
        "        self.input_size = embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        # get task specific embedding\n",
        "        #self.task_embedding = TaskEmbedding(num_tasks=3, embedding_dim= self.input_size)\n",
        "\n",
        "        # dropout\n",
        "        self.dropout_layer = tf.keras.layers.Dropout(rate=dropout)\n",
        "\n",
        "        # Layer Normalization\n",
        "        self.ln_emotion_x = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_emotion_h = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_emotion_c = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "        self.ln_sentiment_x = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_sentiment_h = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_sentiment_c = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "        self.ln_new_x = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_new_h = tf.keras.layers.LayerNormalization(axis=1)\n",
        "        self.ln_new_c = tf.keras.layers.LayerNormalization(axis=1)\n",
        "\n",
        "\n",
        "        # LSTM parameters\n",
        "        self.weight_ih = self.add_weight(shape=(self.input_size, 4 * hidden_size), trainable= trainable)\n",
        "        self.weight_ih_with_dropout = self.dropout_layer(self.weight_ih)\n",
        "        self.weight_hh = self.add_weight(shape=(hidden_size, 4 * hidden_size), trainable= trainable)\n",
        "        self.weight_hh_with_dropout = self.dropout_layer(self.weight_hh)\n",
        "        self.bias = self.add_weight(shape=(4 * hidden_size,), trainable= trainable)\n",
        "        self.bias_with_dropout = self.dropout_layer(self.bias)\n",
        "\n",
        "        # Classification parameters\n",
        "        self.dense_emotion = Dense(units=32, activation='relu')\n",
        "        self.softmax_emotion = Dense(units=num_classes_emotion, activation='softmax')\n",
        "\n",
        "        self.dense_sentiment = Dense(units=32, activation='relu')\n",
        "        self.softmax_sentiment = Dense(units=num_classes_sentiment, activation='softmax')\n",
        "\n",
        "        self.dense_new = Dense(units=32, activation='relu')\n",
        "        self.softmax_new = Dense(units=num_classes_new, activation='softmax') # num_classes_new could be different based on new task considered for fine tuning\n",
        "\n",
        "\n",
        "    def call(self, task, batch_size, hx):\n",
        "        h, c = hx\n",
        "\n",
        "        if task == 'emotion':\n",
        "          ln_x = self.ln_emotion_x\n",
        "          ln_h = self.ln_emotion_h\n",
        "          ln_c = self.ln_emotion_c\n",
        "          dense = self.dense_emotion\n",
        "          soft_max = self.softmax_emotion\n",
        "\n",
        "        elif task == 'sentiment':\n",
        "          ln_x = self.ln_sentiment_x\n",
        "          ln_h = self.ln_sentiment_h\n",
        "          ln_c = self.ln_sentiment_c\n",
        "          dense = self.dense_sentiment\n",
        "          soft_max = self.softmax_sentiment\n",
        "\n",
        "        elif task == 'new':\n",
        "          ln_x = self.ln_new_x\n",
        "          ln_h = self.ln_new_h\n",
        "          ln_c = self.ln_new_c\n",
        "          dense = self.dense_new\n",
        "          soft_max = self.softmax_new\n",
        "\n",
        "        else:\n",
        "          raise ValueError('Key Error')\n",
        "\n",
        "\n",
        "        input = self.initialize_input(batch_size)\n",
        "\n",
        "        gates = ln_x(tf.matmul(input, self.weight_ih_with_dropout)) + ln_h(tf.matmul(h, self.weight_hh_with_dropout)) + self.bias_with_dropout\n",
        "\n",
        "        # Split the gates into input, forget, cell, and output gates\n",
        "        input_gate, forget_gate, cell_gate, output_gate = tf.split(gates, 4, axis=-1)\n",
        "\n",
        "        # Apply sigmoid activation to the gates\n",
        "        input_gate = tf.sigmoid(input_gate)\n",
        "        forget_gate = tf.sigmoid(forget_gate)\n",
        "        cell_gate = tf.tanh(cell_gate)\n",
        "        output_gate = tf.sigmoid(output_gate)\n",
        "\n",
        "        # Update the cell and hidden state\n",
        "        c_new = c * forget_gate + input_gate * cell_gate\n",
        "        h_new = output_gate * tf.tanh(ln_c(c_new))\n",
        "\n",
        "        # Classify using hidden state\n",
        "        dropout_hidden = tf.keras.layers.Dropout(rate=0.3)(h_new)\n",
        "        dense_output = dense(dropout_hidden)\n",
        "        dropout_dense = tf.keras.layers.Dropout(rate=0.2)(dense_output)\n",
        "        output = soft_max(dropout_dense)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def initialize_hidden_state(self, batch_size): # actually, not necessary, cause gets inputs from encoder\n",
        "      return [tf.zeros((batch_size, self.hidden_size)), tf.zeros((batch_size, self.hidden_size))]\n",
        "\n",
        "    def initialize_input(self, batch_size):\n",
        "      return [tf.zeros((batch_size, self.input_size)), tf.zeros((batch_size, self.input_size))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m8getXeUqiv",
        "outputId": "23668068-5457-4635-9e06-a7f896542711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2, 64, 32)\n"
          ]
        }
      ],
      "source": [
        "ln_no_emb = LNLSTMClassifier_no_emb(32, 256)\n",
        "a = ln_no_emb.initialize_input(64)\n",
        "print(np.shape(a))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f97wzawCvnCT"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oIlbCa_JoLil"
      },
      "outputs": [],
      "source": [
        "# Optimizer\n",
        "import tensorflow as tf\n",
        "optimizer = tf.keras.optimizers.legacy.Adam(0.001)\n",
        "\n",
        "#Loss\n",
        "def loss_function(real, pred):\n",
        "  cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "  loss = cross_entropy(y_true= real, y_pred= pred)\n",
        "  loss = tf.reduce_mean(loss)\n",
        "  return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jXbguEsky-gI"
      },
      "outputs": [],
      "source": [
        "# Define Models\n",
        "batch_size = batch_size\n",
        "Encoder = LNLSTMCell(embedding_dim= 100, hidden_size= 128)\n",
        "Classifier = LNLSTMClassifier_with_Attention(embedding_dim= 16, hidden_size= 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "NucsFr7RycYv"
      },
      "outputs": [],
      "source": [
        "# Path to save models\n",
        "model_save_name= \"LNLSTM/with_attention.ckpt\"\n",
        "path= F\"/content/gdrive/My Drive/Model_checkpoints/{model_save_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "U1kYzQjYyz7z"
      },
      "outputs": [],
      "source": [
        "# Checkpoint_save\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optiimizer=optimizer,\n",
        "                                 Encoder=Encoder,\n",
        "                                 Classifier=Classifier)\n",
        "# Checkpoint_lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "lg0wHkSF08G6"
      },
      "outputs": [],
      "source": [
        "# Train Step\n",
        "\n",
        "def train_step(task, text, label):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = tf.TensorArray(tf.float32, size= np.shape(text)[1])\n",
        "    h, c = Encoder.initialize_hidden_state(batch_size=batch_size)\n",
        "    # Encoding\n",
        "    for t in range(np.shape(text)[1]):\n",
        "      h, c = Encoder.call(task, text[:, t], [h,c])\n",
        "      outputs = outputs.write(t, h)\n",
        "    outputs = outputs.stack()\n",
        "    outputs = tf.transpose(outputs, [1,0,2])\n",
        "\n",
        "    task_index = 0\n",
        "    if task == 'emotion':\n",
        "      task_indices = tf.constant([0 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'sentiment':\n",
        "      task_indices = tf.constant([1 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'new':\n",
        "      task_indices = tf.constant([2 for i in range(batch_size)], dtype=tf.int32)\n",
        "    else:\n",
        "      raise ValueError('Key error')\n",
        "    # Classification\n",
        "    out_probs, _ = Classifier.call(task=task, task_indices= task_indices, hx=[h,c], encoder_outputs = outputs)\n",
        "\n",
        "    # Compute accuracy\n",
        "    predicted_labels = tf.argmax(out_probs, axis=-1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(label, predicted_labels), dtype=tf.float32))\n",
        "\n",
        "    # Loss\n",
        "    loss = loss_function(label, out_probs)\n",
        "\n",
        "    # Get the watched variables based on task\n",
        "    variables = Encoder.trainable_variables + Classifier.trainable_variables\n",
        "\n",
        "    # Compute gradients only for watched variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "D9hWbnnLr_I-"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "steps_emotion= len(emotion_text)//batch_size\n",
        "steps_sentiment = len(yelp_text)//batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF4hXlbi1ens",
        "outputId": "27b55672-3843-40f8-bab4-15766d138571"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Loss Sentiment0.1852\n",
            "Epoch 1 Accuracy Sentiment0.9459\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 Loss Emotion0.1882\n",
            "Epoch 2 Accuracy Emotion0.9178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_33/gamma:0', 'layer_normalization_33/beta:0', 'layer_normalization_34/gamma:0', 'layer_normalization_34/beta:0', 'layer_normalization_35/gamma:0', 'layer_normalization_35/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_42/gamma:0', 'luong_attention_2/layer_normalization_42/beta:0', 'layer_normalization_45/gamma:0', 'layer_normalization_45/beta:0', 'layer_normalization_46/gamma:0', 'layer_normalization_46/beta:0', 'layer_normalization_47/gamma:0', 'layer_normalization_47/beta:0', 'dense_30/kernel:0', 'dense_30/bias:0', 'dense_31/kernel:0', 'dense_31/bias:0', 'dense_32/kernel:0', 'dense_32/bias:0', 'dense_33/kernel:0', 'dense_33/bias:0', 'dense_34/kernel:0', 'dense_34/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss Sentiment0.1241\n",
            "Epoch 3 Accuracy Sentiment0.9665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_36/gamma:0', 'layer_normalization_36/beta:0', 'layer_normalization_37/gamma:0', 'layer_normalization_37/beta:0', 'layer_normalization_38/gamma:0', 'layer_normalization_38/beta:0', 'Variable:0', 'Variable:0', 'Variable:0', 'luong_attention_2/layer_normalization_43/gamma:0', 'luong_attention_2/layer_normalization_43/beta:0', 'layer_normalization_48/gamma:0', 'layer_normalization_48/beta:0', 'layer_normalization_49/gamma:0', 'layer_normalization_49/beta:0', 'layer_normalization_50/gamma:0', 'layer_normalization_50/beta:0', 'dense_35/kernel:0', 'dense_35/bias:0', 'dense_36/kernel:0', 'dense_36/bias:0', 'dense_37/kernel:0', 'dense_37/bias:0', 'dense_38/kernel:0', 'dense_38/bias:0', 'dense_39/kernel:0', 'dense_39/bias:0', 'Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss Emotion0.1694\n",
            "Epoch 4 Accuracy Emotion0.9173\n"
          ]
        }
      ],
      "source": [
        "epochs = 4\n",
        "losses_emotion = []\n",
        "losses_sentiment = []\n",
        "\n",
        "accuracies_emotion = []\n",
        "accuracies_sentiment = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  if epoch % 2 == 0:\n",
        "    task = 'sentiment'\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    for (batch, (text, label)) in enumerate(train_sentiment.take(steps_sentiment)):\n",
        "      batch_loss, batch_accuracy = train_step(task, text, label)\n",
        "      total_loss += batch_loss\n",
        "      total_accuracy += batch_accuracy\n",
        "\n",
        "    print('Epoch {} Loss Sentiment{:.4f}'.format((epoch+1)//2,\n",
        "                                        total_loss / steps_sentiment))\n",
        "    print('Epoch {} Accuracy Sentiment{:.4f}'.format(epoch+1,\n",
        "                                        total_accuracy / steps_sentiment))\n",
        "    losses_sentiment.append(total_loss / steps_sentiment)\n",
        "    accuracies_sentiment.append(total_accuracy / steps_sentiment)\n",
        "\n",
        "  else:\n",
        "    task = 'emotion'\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    for (batch, (text, label)) in enumerate(train_emotion.take(steps_emotion)):\n",
        "      batch_loss, batch_accuracy = train_step(task, text, label)\n",
        "      total_loss += batch_loss\n",
        "      total_accuracy += batch_accuracy\n",
        "\n",
        "    #if (epoch+1) % 6 == 0:\n",
        "    #  checkpoint.save(file_prefix = path)\n",
        "\n",
        "    print('Epoch {} Loss Emotion{:.4f}'.format(epoch//2,\n",
        "                                        total_loss / steps_emotion))\n",
        "    print('Epoch {} Accuracy Emotion{:.4f}'.format(epoch+1,\n",
        "                                        total_accuracy / steps_emotion))\n",
        "    losses_emotion.append(total_loss / steps_emotion)\n",
        "    accuracies_emotion.append(total_accuracy / steps_emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "WrG4IVZz88ZP",
        "outputId": "2b45b6da-28f8-4285-dcf3-ea09d24ce2db"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample accuracy data for 8 training epochs\n",
        "epoch_numbers = [1, 2, 3, 4, 5, 6, 7, 8,9]\n",
        "accuracies = accuracies_sentiment_0 + accuracies_sentiment\n",
        "\n",
        "\n",
        "# Plotting the accuracies\n",
        "plt.plot(epoch_numbers, accuracies, marker='o', linestyle='-')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('(with Attention)Sentiment Accuracy Over Epochs')\n",
        "\n",
        "# Adding grid for better readability\n",
        "plt.grid(True)\n",
        "\n",
        "# Saving the plot as a PNG file\n",
        "plt.savefig('attention_sentiment_accuracy.png')\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "yLF7Xl3s9xCW",
        "outputId": "8fd30169-51f4-4b10-b7a0-cfb639a909c1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample accuracy data for 8 training epochs\n",
        "epoch_numbers = [1, 2, 3, 4, 5, 6, 7, 8,9]\n",
        "accuracies = accuracies_emotion_0 + accuracies_emotion\n",
        "\n",
        "\n",
        "# Plotting the accuracies\n",
        "plt.plot(epoch_numbers, accuracies, marker='o', linestyle='-')\n",
        "\n",
        "# Adding labels and title\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('(with Attention) Emotion Accuracy Over Epochs')\n",
        "\n",
        "# Adding grid for better readability\n",
        "plt.grid(True)\n",
        "\n",
        "# Saving the plot as a PNG file\n",
        "plt.savefig('attention_emotion_accuracy.png')\n",
        "\n",
        "# Displaying the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "chG83dRUQRai"
      },
      "outputs": [],
      "source": [
        "losses_sentiment_0 = losses_sentiment\n",
        "accuracies_sentiment_0 = accuracies_sentiment\n",
        "losses_emotion_0 = losses_emotion\n",
        "accuracies_emotion_0 = accuracies_emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eREXHvq0QUI5",
        "outputId": "71ab329c-20ef-416c-8a73-d29bb438fd24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=0.45753205>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.56189907>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.68409455>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.8066907>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.9016426>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.95653045>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.98397434>]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracies_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNyFksUVQXpJ",
        "outputId": "df79dd27-b19e-4516-f9b0-2493d5580186"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=1.2710248>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.95323414>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.65045595>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.43758708>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.303985>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.22922002>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.1909089>]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses_emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxovmqnbQY3J",
        "outputId": "3ff4b27e-ff17-4275-dd91-d2bbe16bbbbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=0.40360576>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.61346155>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.7502404>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.8408654>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.8894231>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.90889424>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.91778845>]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracies_emotion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEcw_ArwJzXe"
      },
      "outputs": [],
      "source": [
        "# Define Models\n",
        "batch_size = batch_size\n",
        "Encoder_separate = LNLSTMCell(embedding_dim= 100, hidden_size= 256)\n",
        "Classifier_separate = MultiTaskClassifier(embedding_dim= 32, hidden_size= 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CiXzZzoTKAKU"
      },
      "outputs": [],
      "source": [
        "# Train Step\n",
        "\n",
        "def train_step_separate(task, text, label):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    h, c = Encoder_separate.initialize_hidden_state(batch_size=batch_size)\n",
        "    # Encoding\n",
        "    for t in range(np.shape(text)[1]):\n",
        "      h, c = Encoder_separate.call(task, text[:, t], [h,c])\n",
        "\n",
        "    task_index = 0\n",
        "    if task == 'emotion':\n",
        "      task_indices = tf.constant([0 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'sentiment':\n",
        "      task_indices = tf.constant([1 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'new':\n",
        "      task_indices = tf.constant([2 for i in range(batch_size)], dtype=tf.int32)\n",
        "    else:\n",
        "      raise ValueError('Key error')\n",
        "\n",
        "    # Classification\n",
        "    out_probs = Classifier_separate.call(task=task, task_indices= task_indices, hx=[h,c])\n",
        "\n",
        "    # Compute accuracy\n",
        "    predicted_labels = tf.argmax(out_probs, axis=-1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(label, predicted_labels), dtype=tf.float32))\n",
        "\n",
        "    # Loss\n",
        "    loss = loss_function(label, out_probs)\n",
        "\n",
        "    # Get the watched variables\n",
        "    variables = Encoder_separate.trainable_variables + Classifier_separate.trainable_variables\n",
        "\n",
        "    # Compute gradients only for watched variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    # Apply gradients to the watched variables\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fw2qXmGCJMfZ"
      },
      "outputs": [],
      "source": [
        "epochs = 14\n",
        "losses_emotion_separate = []\n",
        "losses_sentiment_separate = []\n",
        "\n",
        "accuracies_emotion_separate = []\n",
        "accuracies_sentiment_separate = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  if epoch % 2 == 0:\n",
        "    task = 'sentiment'\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    for (batch, (text, label)) in enumerate(train_sentiment.take(steps_sentiment)):\n",
        "      batch_loss, batch_accuracy = train_step(task, text, label)\n",
        "      total_loss += batch_loss\n",
        "      total_accuracy += batch_accuracy\n",
        "\n",
        "    print('Epoch {} Loss Sentiment{:.4f}'.format((epoch+1)//2,\n",
        "                                        total_loss / steps_sentiment))\n",
        "    print('Epoch {} Accuracy Sentiment{:.4f}'.format(epoch+1,\n",
        "                                        total_accuracy / steps_sentiment))\n",
        "    losses_sentiment_separate.append(total_loss / steps_sentiment)\n",
        "    accuracies_sentiment_separate.append(total_accuracy / steps_sentiment)\n",
        "\n",
        "  else:\n",
        "    task = 'emotion'\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    for (batch, (text, label)) in enumerate(train_emotion.take(steps_emotion)):\n",
        "      batch_loss, batch_accuracy = train_step(task, text, label)\n",
        "      total_loss += batch_loss\n",
        "      total_accuracy += batch_accuracy\n",
        "\n",
        "    #if (epoch+1) % 6 == 0:\n",
        "    #  checkpoint.save(file_prefix = path)\n",
        "\n",
        "    print('Epoch {} Loss Emotion{:.4f}'.format(epoch//2,\n",
        "                                        total_loss / steps_emotion))\n",
        "    print('Epoch {} Accuracy Emotion{:.4f}'.format(epoch+1,\n",
        "                                        total_accuracy / steps_emotion))\n",
        "    losses_emotion_separate.append(total_loss / steps_emotion)\n",
        "    accuracies_emotion_separate.append(total_accuracy / steps_emotion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5mCp_NQVXfK"
      },
      "outputs": [],
      "source": [
        "batch_size = batch_size\n",
        "Encoder_no_emb = LNLSTMCell(embedding_dim= 100, hidden_size= 256)\n",
        "Classifier_no_emb = LNLSTMClassifier_no_emb(embedding_dim= 32, hidden_size= 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pBXCJI4TVG2K"
      },
      "outputs": [],
      "source": [
        "# Train Step\n",
        "\n",
        "def train_step_no_emb(task, text, label):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    h, c = Encoder_no_emb.initialize_hidden_state(batch_size=batch_size)\n",
        "    # Encoding\n",
        "    for t in range(np.shape(text)[1]):\n",
        "      h, c = Encoder_no_emb.call(task, text[:, t], [h,c])\n",
        "\n",
        "    task_index = 0\n",
        "    if task == 'emotion':\n",
        "      task_indices = tf.constant([0 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'sentiment':\n",
        "      task_indices = tf.constant([1 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'new':\n",
        "      task_indices = tf.constant([2 for i in range(batch_size)], dtype=tf.int32)\n",
        "    else:\n",
        "      raise ValueError('Key error')\n",
        "\n",
        "    # Classification\n",
        "    out_probs = Classifier_no_emb.call(task=task, batch_size=batch_size, hx=[h,c])\n",
        "\n",
        "    # Compute accuracy\n",
        "    predicted_labels = tf.argmax(out_probs, axis=-1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(label, predicted_labels), dtype=tf.float32))\n",
        "\n",
        "    # Loss\n",
        "    loss = loss_function(label, out_probs)\n",
        "\n",
        "    # Get the watched variables\n",
        "    variables = Encoder_no_emb.trainable_variables + Classifier_no_emb.trainable_variables\n",
        "\n",
        "    # Compute gradients only for watched variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    # Apply gradients to the watched variables\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l01abpaW2oO"
      },
      "outputs": [],
      "source": [
        "epochs = 14\n",
        "losses_emotion_no_emb= []\n",
        "losses_sentiment_no_emb = []\n",
        "\n",
        "accuracies_emotion_no_emb = []\n",
        "accuracies_sentiment_no_emb = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  if epoch % 2 == 0:\n",
        "    task = 'sentiment'\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    for (batch, (text, label)) in enumerate(train_sentiment.take(steps_sentiment)):\n",
        "      batch_loss, batch_accuracy = train_step(task, text, label)\n",
        "      total_loss += batch_loss\n",
        "      total_accuracy += batch_accuracy\n",
        "\n",
        "    print('Epoch {} Loss Sentiment{:.4f}'.format((epoch+1)//2,\n",
        "                                        total_loss / steps_sentiment))\n",
        "    print('Epoch {} Accuracy Sentiment{:.4f}'.format(epoch+1,\n",
        "                                        total_accuracy / steps_sentiment))\n",
        "    losses_sentiment_no_emb.append(total_loss / steps_sentiment)\n",
        "    accuracies_sentiment_no_emb.append(total_accuracy / steps_sentiment)\n",
        "\n",
        "  else:\n",
        "    task = 'emotion'\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    for (batch, (text, label)) in enumerate(train_emotion.take(steps_emotion)):\n",
        "      batch_loss, batch_accuracy = train_step(task, text, label)\n",
        "      total_loss += batch_loss\n",
        "      total_accuracy += batch_accuracy\n",
        "\n",
        "    #if (epoch+1) % 6 == 0:\n",
        "    #  checkpoint.save(file_prefix = path)\n",
        "\n",
        "    print('Epoch {} Loss Emotion{:.4f}'.format(epoch//2,\n",
        "                                        total_loss / steps_emotion))\n",
        "    print('Epoch {} Accuracy Emotion{:.4f}'.format(epoch+1,\n",
        "                                        total_accuracy / steps_emotion))\n",
        "    losses_emotion_no_emb.append(total_loss / steps_emotion)\n",
        "    accuracies_emotion_no_emb.append(total_accuracy / steps_emotion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC7EF0k7iKVB"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ZORP588jPD4q"
      },
      "outputs": [],
      "source": [
        "# Train Step\n",
        "def evaluate(task, text, label):\n",
        "\n",
        "    outputs = tf.TensorArray(tf.float32, size= np.shape(text)[1])\n",
        "    h, c = Encoder.initialize_hidden_state(batch_size=batch_size)\n",
        "    # Encoding\n",
        "    for t in range(np.shape(text)[1]):\n",
        "      h, c = Encoder.call(task, text[:, t], [h,c])\n",
        "      outputs = outputs.write(t, h)\n",
        "    outputs = outputs.stack()\n",
        "    outputs = tf.transpose(outputs, [1,0,2])\n",
        "\n",
        "    task_index = 0\n",
        "    if task == 'emotion':\n",
        "      task_indices = tf.constant([0 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'sentiment':\n",
        "      task_indices = tf.constant([1 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'new':\n",
        "      task_indices = tf.constant([2 for i in range(batch_size)], dtype=tf.int32)\n",
        "    else:\n",
        "      raise ValueError('Key error')\n",
        "    # Classification\n",
        "    out_probs, _ = Classifier.call(task=task, task_indices= task_indices, hx=[h,c], encoder_outputs = outputs)\n",
        "\n",
        "    # Compute accuracy\n",
        "    predicted_labels = tf.argmax(out_probs, axis=-1)\n",
        "    accuracy = (tf.reduce_mean(tf.cast(tf.equal(label, predicted_labels), dtype=tf.float32)))\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "krTKgrMv0Mvg"
      },
      "outputs": [],
      "source": [
        "ds_name = \"emotion_test.csv\"\n",
        "path= F\"/content/gdrive/My Drive/Database/{ds_name}\"\n",
        "ds = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "moXQWEJs0P1r"
      },
      "outputs": [],
      "source": [
        "emotion_text_test = ds['text']\n",
        "emotion_label_test = ds['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztLDhiRM0jQK",
        "outputId": "d6faf6c6-4bcb-43f0-d546-1fa83cd12336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "print(len(emotion_text_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiPzCOT10r0J",
        "outputId": "02240a18-2d7a-48b2-9a7d-9e4ffcd36edf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-79cb1ed4c48f>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  Text = np.array([self.preprocess_sentence(w) for w in text])\n"
          ]
        }
      ],
      "source": [
        "buffer_size_emotion = 150\n",
        "batch_size = 120\n",
        "max_len = 25\n",
        "\n",
        "preprocess = Preprocess_classification(vocab)\n",
        "test_emotion = preprocess.create_dataset(emotion_text_test, emotion_label_test, max_len, buffer_size_emotion, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "fLtSaij_08U0"
      },
      "outputs": [],
      "source": [
        "task = 'emotion'\n",
        "for (batch, (text, label)) in enumerate(test_emotion.take(1)):\n",
        "  batch_accuracy = evaluate(task, text, label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSiGz4TJ2m0U",
        "outputId": "cfc408ab-c308-4b53-c9cb-d4c91cab4f6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.8375>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC_FGtlJiCoq"
      },
      "source": [
        "# Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q8QrSDHASfH"
      },
      "source": [
        "## Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mxDr4BoCSgz"
      },
      "outputs": [],
      "source": [
        "ds_name = \"imdb_train.csv\"\n",
        "path= F\"/content/gdrive/My Drive/Database/{ds_name}\"\n",
        "ds = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMZiZXcqCe9G"
      },
      "outputs": [],
      "source": [
        "imdb_text = ds['text']\n",
        "imdb_label = ds['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR0IJAMEbB2d",
        "outputId": "a9d78a14-2d0d-4c60-dc56-2e0907edae11"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-79cb1ed4c48f>:35: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  Text = np.array([self.preprocess_sentence(w) for w in text])\n"
          ]
        }
      ],
      "source": [
        "buffer_size_imdb = 2100\n",
        "batch_size_imdb = 64\n",
        "max_len = 25\n",
        "\n",
        "imdb_process = Preprocess_classification(vocab)\n",
        "train_imdb = imdb_process.create_dataset(imdb_text, imdb_label, max_len, buffer_size_imdb, batch_size_imdb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbhmMsiamRrN",
        "outputId": "8e2b3f53-d98b-4983-a2fd-284f1857fc15"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "# On base model\n",
        "classifier_imdb_base = Basic_Classifier(batch_size= 64, units= 256, num_classes= 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM8g-I18s1iS",
        "outputId": "ca9c5ee3-2281-4641-ae9d-760e46bd7b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.6859\n",
            "Epoch 1 Accuracy 18.1094\n",
            "Epoch 2 Loss 0.4433\n",
            "Epoch 2 Accuracy 24.9688\n",
            "Epoch 3 Loss 0.1973\n",
            "Epoch 3 Accuracy 28.6562\n",
            "Epoch 4 Loss 0.0725\n",
            "Epoch 4 Accuracy 30.3750\n",
            "Epoch 5 Loss 0.0189\n",
            "Epoch 5 Accuracy 30.8438\n",
            "Epoch 6 Loss 0.0076\n",
            "Epoch 6 Accuracy 30.9531\n",
            "Epoch 7 Loss 0.0046\n",
            "Epoch 7 Accuracy 30.9844\n",
            "Epoch 8 Loss 0.0034\n",
            "Epoch 8 Accuracy 30.9844\n",
            "Epoch 9 Loss 0.0028\n",
            "Epoch 9 Accuracy 30.9844\n"
          ]
        }
      ],
      "source": [
        "losses_imdb_base, accuracies_imdb_base = train_epoch_base(classifier_imdb_base, train_imdb, len(imdb_text)//batch_size, 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oBTR0e4l6Xf"
      },
      "outputs": [],
      "source": [
        "Encoder.trainable = False\n",
        "Classifier_fine_tune = LNLSTMClassifier(embedding_dim= 32, hidden_size= 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjGSXt64lM_3"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "steps_new= len(imdb_text)//batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8u0abiOREbJo"
      },
      "outputs": [],
      "source": [
        "# Train Step\n",
        "\n",
        "def train_step(task, text, label):\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    h, c = Encoder.initialize_hidden_state(batch_size=batch_size)\n",
        "    # Encoding\n",
        "    for t in range(np.shape(text)[1]):\n",
        "      h, c = Encoder.call(task, text[:, t], [h,c])\n",
        "    task_index = 0\n",
        "    if task == 'emotion':\n",
        "      task_indices = tf.constant([0 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'sentiment':\n",
        "      task_indices = tf.constant([1 for i in range(batch_size)], dtype=tf.int32)\n",
        "    elif task == 'new':\n",
        "      task_indices = tf.constant([2 for i in range(batch_size)], dtype=tf.int32)\n",
        "    else:\n",
        "      raise ValueError('Key error')\n",
        "\n",
        "    # Classification\n",
        "    out_probs = Classifier_fine_tune.call(task=task, task_indices= task_indices, hx=[h,c])\n",
        "\n",
        "    # Compute accuracy\n",
        "    predicted_labels = tf.argmax(out_probs, axis=-1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(tf.equal(label, predicted_labels), dtype=tf.float32))\n",
        "\n",
        "    # Loss\n",
        "    loss = loss_function(label, out_probs)\n",
        "\n",
        "    # Get the watched variables\n",
        "    variables = Encoder.trainable_variables + Classifier_fine_tune.trainable_variables\n",
        "\n",
        "    # Compute gradients only for watched variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "    # Apply gradients to the watched variables\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKNyeZLZKjQ7",
        "outputId": "53e851a1-f0f2-483a-9097-b9a547c54ebe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss imdb0.3530\n",
            "Epoch 1 Accuracy imdb0.8679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['Variable:0', 'Variable:0', 'Variable:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Loss imdb0.3203\n",
            "Epoch 2 Accuracy imdb0.8896\n"
          ]
        }
      ],
      "source": [
        "epochs = 9\n",
        "losses_imdb= []\n",
        "\n",
        "accuracies_imdb = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    task = 'new'\n",
        "    total_loss = 0\n",
        "    total_accuracy = 0\n",
        "    for (batch, (text, label)) in enumerate(train_imdb.take(steps_new)):\n",
        "      batch_loss, batch_accuracy = train_step(task, text, label)\n",
        "      total_loss += batch_loss\n",
        "      total_accuracy += batch_accuracy\n",
        "\n",
        "    #if (epoch+1) % 6 == 0:\n",
        "    #  checkpoint.save(file_prefix = path)\n",
        "\n",
        "    print('Epoch {} Loss imdb{:.4f}'.format(epoch+1,\n",
        "                                        total_loss / steps_new))\n",
        "    print('Epoch {} Accuracy imdb{:.4f}'.format(epoch+1,\n",
        "                                        total_accuracy / steps_new))\n",
        "    losses_imdb.append(total_loss / steps_new)\n",
        "    accuracies_imdb.append(total_accuracy / steps_new)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofNI__5-nqyR",
        "outputId": "9b102800-a47d-4d99-aec6-3a8873b25bf8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=0.35303882>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.3203489>]"
            ]
          },
          "execution_count": 139,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "losses_imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sX74jGhuol_O",
        "outputId": "0754418c-c0d4-4cc7-8003-5e6a6412e539"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=float32, numpy=0.8679435>,\n",
              " <tf.Tensor: shape=(), dtype=float32, numpy=0.8896169>]"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "accuracies_imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vh7Jkq7UpuTK"
      },
      "outputs": [],
      "source": [
        "l = [float(i) for i in losses_imdb]\n",
        "a = [float(i) for i in accuracies_imdb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "zFRLW1CopZId",
        "outputId": "a519525f-f9e9-4db9-8323-69ee0ca76a07"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "losses = l\n",
        "accuracies = a\n",
        "\n",
        "# Create subplots for losses and accuracies\n",
        "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,3), sharex=True)\n",
        "\n",
        "# Plot for losses\n",
        "ax1.plot(epochs, losses, marker='o', color='b', label='Loss')\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.set_title('   Fine Tuning Loss and Accuracy\\n', fontsize=14)\n",
        "ax1.legend()\n",
        "\n",
        "# Plot for accuracies\n",
        "ax2.plot(epochs, accuracies, marker='o', color='g', label='Accuracy')\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy', fontsize=12)\n",
        "ax2.legend()\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plots as images (optional)\n",
        "plt.savefig('loss_accuracy_plot.png', dpi=300)\n",
        "\n",
        "# Show the plots\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MPj-6fOqo85"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "e7w4AhWnpFl5",
        "Kjp2PPzZQkX-"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
